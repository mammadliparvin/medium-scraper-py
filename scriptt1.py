# -*- coding: utf-8 -*-
"""scriptt1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lMueRy0oMQc2HlvsN3xA93olMlH20_wC
"""

import os
import requests
import re
from bs4 import BeautifulSoup
from google.colab import files

def get_page():
    url = "https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"  # Set the URL directly
    res = requests.get(url)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, 'html.parser')
    return soup

"""#remove all the html tags and replace some with specific strings"""

def clean(text):
    rep = {"<br>": "\n", "<br/>": "\n", "<li>":  "\n"}
    rep = dict((re.escape(k), v) for k, v in rep.items())
    pattern = re.compile("|".join(rep.keys()))
    text = pattern.sub(lambda m: rep[re.escape(m.group(0))], text)
    text = re.sub('\<(.*?)\>', '', text)
    return text

def collect_text(soup, url):
    text = f'url: {url}\n\n'
    para_text = soup.find_all('p')
    for para in para_text:
        text += f"{para.text}\n\n"
    return text

"""#saving file"""

def save_file(text, url):
    if not os.path.exists('./scraped_articles'):
        os.mkdir('./scraped_articles')
        name = url.split("/")[-1]
    fname = f'scraped_articles/{name}.txt'
    with open(fname, 'w', encoding='utf-8') as f:
        f.write(text)

    print(f'File saved in directory {fname}')
    files.download(fname)

if __name__ == '__main__':
    url = "https://medium.com/@subashgandyer/papa-what-is-a-neural-network-c5e5cc427c7"
    soup = get_page()
    if soup:
        text = collect_text(soup, url)
        save_file(text, url)